{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of SigModelv2x3.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/raahatg21/Signature_Verification/blob/raahatg21-siamese/sigmodelv2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "NtzX4QokVZpY"
      },
      "cell_type": "markdown",
      "source": [
        "# Signature Verification v2.3 (changed)"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "OhKsrlGZVeBR"
      },
      "cell_type": "markdown",
      "source": [
        "## Using Siamese Network and self-preprocessing the data"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "8sOGYOkJWwT2"
      },
      "cell_type": "markdown",
      "source": [
        "##Workflow:\n",
        "\n",
        "###Data Preprocessing\n",
        "* go to the required directories\n",
        "* select pairs of images\n",
        "\n",
        "* preprocess pairs\n",
        "  * load images\n",
        "  * convert to np array\n",
        "  * format to correct size, etc\n",
        "  * join them to form a pair and append in the list of pairs\n",
        "\n",
        "* add the corresponding label (genuine-genuine pair or genuine-forged pair)\n",
        "* divide into: 40 authors training, 7 validation, 7 testing\n",
        "* shuffle, but labels must remain corresponding to the right pairs\n",
        "        \n",
        "###Model Accessories\n",
        "* define eucledian distance\n",
        "* define loss\n",
        "* define accuracy measure\n",
        "        \n",
        "###Defining the Model\n",
        "* define one branch\n",
        "* make two branches and merge them\n",
        "* mark correct input-ouput\n",
        "* compile the model\n",
        "        \n",
        "###Train and Evaluate"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "xV1MK-3nUPdT",
        "outputId": "a36ed9ff-1c89-4f78-a71f-ae703cfb4541",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "''' Directory structure:\n",
        "    Data_for_3\n",
        "    --> 54 Authors (013, 017, 018 etc)\n",
        "        --> Genuine (24 sign each)\n",
        "        --> Forged (~12 sign each)\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Directory structure:\\n    Data_for_3\\n    --> 54 Authors (013, 017, 018 etc)\\n        --> Genuine (24 sign each)\\n        --> Forged (~12 sign each)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "S24MjsW1VdbO",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "qJewYHLnaUpe",
        "outputId": "84d782d3-5f7d-4e61-f646-5868f3f605ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 662
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install -I keras==2.1.6"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras==2.1.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/54/e8/eaff7a09349ae9bd40d3ebaf028b49f5e2392c771f294910f75bb608b241/Keras-2.1.6-py2.py3-none-any.whl (339kB)\n",
            "\u001b[K    100% |████████████████████████████████| 348kB 26.6MB/s \n",
            "\u001b[?25hCollecting pyyaml (from keras==2.1.6)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/a3/1d13970c3f36777c583f136c136f804d70f500168edc1edea6daa7200769/PyYAML-3.13.tar.gz (270kB)\n",
            "\u001b[K    100% |████████████████████████████████| 276kB 29.1MB/s \n",
            "\u001b[?25hCollecting scipy>=0.14 (from keras==2.1.6)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/67/e6/6d4edaceee6a110ecf6f318482f5229792f143e468b34a631f5a0899f56d/scipy-1.2.0-cp36-cp36m-manylinux1_x86_64.whl (26.6MB)\n",
            "\u001b[K    100% |████████████████████████████████| 26.6MB 1.8MB/s \n",
            "\u001b[?25hCollecting six>=1.9.0 (from keras==2.1.6)\n",
            "  Downloading https://files.pythonhosted.org/packages/73/fb/00a976f728d0d1fecfe898238ce23f502a721c0ac0ecfedb80e0d88c64e9/six-1.12.0-py2.py3-none-any.whl\n",
            "Collecting h5py (from keras==2.1.6)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/30/99/d7d4fbf2d02bb30fb76179911a250074b55b852d34e98dd452a9f394ac06/h5py-2.9.0-cp36-cp36m-manylinux1_x86_64.whl (2.8MB)\n",
            "\u001b[K    100% |████████████████████████████████| 2.8MB 9.5MB/s \n",
            "\u001b[?25hCollecting numpy>=1.9.1 (from keras==2.1.6)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7b/74/54c5f9bb9bd4dae27a61ec1b39076a39d359b3fb7ba15da79ef23858a9d8/numpy-1.16.0-cp36-cp36m-manylinux1_x86_64.whl (17.3MB)\n",
            "\u001b[K    100% |████████████████████████████████| 17.3MB 3.4MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyyaml\n",
            "  Running setup.py bdist_wheel for pyyaml ... \u001b[?25l-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/ad/da/0c/74eb680767247273e2cf2723482cb9c924fe70af57c334513f\n",
            "Successfully built pyyaml\n",
            "\u001b[31myellowbrick 0.9 has requirement matplotlib<3.0,>=1.5.1, but you'll have matplotlib 3.0.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mtorchvision 0.2.1 has requirement pillow>=4.1.1, but you'll have pillow 4.0.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mthinc 6.12.1 has requirement wrapt<1.11.0,>=1.10.0, but you'll have wrapt 1.11.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mpymc3 3.6 has requirement joblib<0.13.0, but you'll have joblib 0.13.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mjupyter-console 6.0.0 has requirement prompt-toolkit<2.1.0,>=2.0.0, but you'll have prompt-toolkit 1.0.15 which is incompatible.\u001b[0m\n",
            "\u001b[31mgoogle-colab 0.0.1a1 has requirement six~=1.11.0, but you'll have six 1.12.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mgoogle-cloud-storage 1.8.0 has requirement google-cloud-core<0.29dev,>=0.28.0, but you'll have google-cloud-core 0.29.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mfeaturetools 0.4.1 has requirement pandas>=0.23.0, but you'll have pandas 0.22.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mcufflinks 0.14.6 has requirement plotly>=3.0.0, but you'll have plotly 1.12.12 which is incompatible.\u001b[0m\n",
            "\u001b[31malbumentations 0.1.11 has requirement numpy<1.16.0,>=1.11.1, but you'll have numpy 1.16.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: pyyaml, numpy, scipy, six, h5py, keras\n",
            "Successfully installed h5py-2.9.0 keras-2.2.4 numpy-1.16.0 pyyaml-3.13 scipy-1.2.0 six-1.12.0\n",
            "\u001b[0;31;1mWARNING: The following packages were previously imported in this runtime:\n",
            "  [numpy, scipy, six]\n",
            "You must restart the runtime in order to use newly installed versions.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Tcrk6uRRyMqH",
        "colab_type": "code",
        "outputId": "861d0c48-4ec4-4c42-d763-a972dcf75b1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "keras.__version__  # Make sure it is 2.1.6"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.1.6'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "B2ArXqARYu7Y",
        "outputId": "17226b62-3ccf-4823-af82-610d2e54ce37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "cell_type": "code",
      "source": [
        "# Mounting Google Drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Xj1ia176VLp3",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from keras import layers, optimizers, regularizers\n",
        "from keras.models import Sequential, Model\n",
        "from keras.preprocessing import image\n",
        "from keras import backend as K\n",
        "from keras.models import Model   \n",
        "from keras.layers import * "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ATGnpL7WTU3W",
        "outputId": "e5fe33d2-39f2-45da-b632-a3724f30c3c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "# !ls \"/content/drive/My Drive\"\n",
        "#!ls \"/content/drive/My Drive/Data_for_3\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "013  020  024  028  032  036  040  044\t048  052  056  060  064  068\n",
            "017  021  025  029  033  037  041  045\t049  053  057  061  065  069\n",
            "018  022  026  030  034  038  042  046\t050  054  058  062  066\n",
            "019  023  027  031  035  039  043  047\t051  055  059  063  067\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "3NOhNBKYYxbE",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "BASE_DIR = \"/content/drive/My Drive/Data_for_3\"  # when using Google Drive\n",
        "#BASE_DIR = \"/home/raahat/Documents/Signet/Datasets/Data_for_3\"  # when using local files"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "BDdp9gc2ipVw",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Some functions for loss and accuracy\n",
        "\n",
        "def euclidean_distance(vects):\n",
        "    x, y = vects\n",
        "    return K.sqrt(K.sum(K.square(x - y), axis=1, keepdims=True))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "UPuvxZ5ni3ra",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def eucl_dist_output_shape(shapes):\n",
        "    shape1, shape2 = shapes\n",
        "    return (shape1[0], 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Hq7qP9mOi6XT",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def contrastive_loss(y_true, y_pred):\n",
        "    margin = 1\n",
        "    return K.mean(y_true * K.square(y_pred) + (1 - y_true) * K.square(K.maximum(margin - y_pred, 0)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "xdUlpo9Oi8ra",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def compute_accuracy_roc(predictions, labels):  ## what is use of this?\n",
        "    dmax = np.max(predictions)\n",
        "    dmin = np.min(predictions)\n",
        "    nsame = np.sum(labels == 1)\n",
        "    ndiff = np.sum(labels == 0)\n",
        "\n",
        "    step = 0.01\n",
        "    max_acc = 0\n",
        "    \n",
        "    for d in np.arange(dmin, dmax+step, step):\n",
        "        idx1 = predictions.ravel() <= d\n",
        "        idx2 = predictions.ravel() > d\n",
        "\n",
        "        tpr = float(np.sum(labels[idx1] == 1)) / nsame\n",
        "        tnr = float(np.sum(labels[idx2] == 0)) / ndiff\n",
        "        acc = 0.5 * (tpr + tnr)\n",
        "\n",
        "        if (acc > max_acc):\n",
        "            max_acc = acc\n",
        "\n",
        "        return max_acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "M0ywxu8NjBP9",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def compute_accuracy(predictions, labels):  ## what is use of this?\n",
        "    return labels[predictions.ravel() < 0.5].mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "FdQpktpdjRbZ",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Parameters and Variables\n",
        "\n",
        "height =  256\n",
        "width =  256\n",
        "# image is greyscaled (channels = 1)\n",
        "input_shape = (height, width, 1)\n",
        "\n",
        "epochs = 20\n",
        "batch_size = 128"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Iyb2QRUXkbxr",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Getting and preprocessing the data\n",
        "\n",
        "authors = os.listdir(BASE_DIR)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "R4KbzPdtkgq-",
        "outputId": "1a49dc98-ccb0-4dd0-c64d-00123bcd0e44",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 555
        }
      },
      "cell_type": "code",
      "source": [
        "# Training Data\n",
        "\n",
        "tr_pairs = []\n",
        "tr_labels = []\n",
        "\n",
        "for counter, author in enumerate(authors[0:41], 1):\n",
        "    gen_dir = os.path.join(BASE_DIR, author, 'Genuine')\n",
        "    for_dir = os.path.join(BASE_DIR, author, 'Forged')\n",
        "\n",
        "    gen_list = os.listdir(gen_dir)\n",
        "    for_list = os.listdir(for_dir)\n",
        "\n",
        "    gen_num = len(gen_list)\n",
        "    for_num = len(for_list)\n",
        "\n",
        "    # Genuine-Genuine\n",
        "    for i in range(gen_num):\n",
        "        for j in range(i+1, gen_num):\n",
        "            file1 = gen_list[i]\n",
        "            file2 = gen_list[j]\n",
        "            \n",
        "            try:\n",
        "              img1 = image.load_img(os.path.join(gen_dir, file1), grayscale = True, target_size=(height, width))\n",
        "              img1 = image.img_to_array(img1)\n",
        "              img1 = img1.astype('float32')\n",
        "              img1 /= 255\n",
        "\n",
        "              img2 = image.load_img(os.path.join(gen_dir, file2), grayscale = True, target_size=(height, width))\n",
        "              img2 = image.img_to_array(img2)\n",
        "              img2 = img2.astype('float32')\n",
        "              img2 /= 255\n",
        "\n",
        "              tr_pairs += [[img1, img2]] \n",
        "              tr_labels += [[1]]  ## why not tr_labels += [1]\n",
        "            \n",
        "            except:\n",
        "              a = 2\n",
        "\n",
        "    # Genuine-Forged\n",
        "    for k in range(gen_num):\n",
        "        for l in range(for_num):\n",
        "            file3 = gen_list[k]\n",
        "            file4 = for_list[l]\n",
        "            \n",
        "            try:\n",
        "              img3 = image.load_img(os.path.join(gen_dir, file3), grayscale = True, target_size=(height, width))\n",
        "              img3 = image.img_to_array(img3)\n",
        "              img3 = img3.astype('float32')\n",
        "              img3 /= 255\n",
        "\n",
        "              img4 = image.load_img(os.path.join(for_dir, file4), grayscale = True, target_size=(height, width))\n",
        "              img4 = image.img_to_array(img4)\n",
        "              img4 = img4.astype('float32')\n",
        "              img4 /= 255\n",
        "\n",
        "              tr_pairs += [[img3, img4]]  \n",
        "              tr_labels += [[0]]  ## why not tr_labels += [0]\n",
        "            \n",
        "            except:\n",
        "              a = 2\n",
        "              \n",
        "    print(counter, len(tr_pairs))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 564\n",
            "2 1128\n",
            "3 1692\n",
            "4 2256\n",
            "5 2916\n",
            "6 3384\n",
            "7 3852\n",
            "8 4512\n",
            "9 5076\n",
            "10 5736\n",
            "11 6300\n",
            "12 6864\n",
            "13 7428\n",
            "14 8160\n",
            "15 8724\n",
            "16 9192\n",
            "17 9756\n",
            "18 10320\n",
            "19 10788\n",
            "20 11352\n",
            "21 11820\n",
            "22 12384\n",
            "23 12948\n",
            "24 13512\n",
            "25 14076\n",
            "26 14544\n",
            "27 15204\n",
            "28 15768\n",
            "29 16263\n",
            "30 16827\n",
            "31 17583\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ttTRMH27g1o6",
        "outputId": "ac3b6e2d-ff17-41ba-ebf2-acac71083b77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "cell_type": "code",
      "source": [
        "# Validation Data\n",
        "\n",
        "vl_pairs = []\n",
        "vl_labels = []\n",
        "\n",
        "for counter, author2 in enumerate(authors[41:48], 1):\n",
        "    gen_dir2 = os.path.join(BASE_DIR, author2, 'Genuine')\n",
        "    for_dir2 = os.path.join(BASE_DIR, author2, 'Forged')\n",
        "\n",
        "    gen_list2 = os.listdir(gen_dir2)\n",
        "    for_list2 = os.listdir(for_dir2)\n",
        "\n",
        "    gen_num2 = len(gen_list2)\n",
        "    for_num2 = len(for_list2)\n",
        "\n",
        "    # Genuine-Genuine\n",
        "    for i in range(gen_num2):\n",
        "        for j in range(i+1, gen_num2):\n",
        "            file1 = gen_list2[i]\n",
        "            file2 = gen_list2[j]\n",
        "            \n",
        "            # try\n",
        "            img1 = image.load_img(os.path.join(gen_dir2, file1), grayscale = True, target_size=(height, width))\n",
        "            img1 = image.img_to_array(img1)\n",
        "            img1 = img1.astype('float32')\n",
        "            img1 /= 255\n",
        "\n",
        "            img2 = image.load_img(os.path.join(gen_dir2, file2), grayscale = True, target_size=(height, width))\n",
        "            img2 = image.img_to_array(img2)\n",
        "            img2 = img2.astype('float32')\n",
        "            img2 /= 255\n",
        "\n",
        "            vl_pairs += [[img1, img2]] \n",
        "            vl_labels += [[1]]  ## why not tr_labels += [1]\n",
        "              \n",
        "            # except\n",
        "\n",
        "    # Genuine-Forged\n",
        "    for k in range(gen_num2):\n",
        "        for l in range(for_num2):\n",
        "            file3 = gen_list2[k]\n",
        "            file4 = for_list2[l]\n",
        "\n",
        "            # try\n",
        "            img3 = image.load_img(os.path.join(gen_dir2, file3), grayscale = True, target_size=(height, width))\n",
        "            img3 = image.img_to_array(img3)\n",
        "            img3 = img3.astype('float32')\n",
        "            img3 /= 255\n",
        "\n",
        "            img4 = image.load_img(os.path.join(for_dir2, file4), grayscale = True, target_size=(height, width))\n",
        "            img4 = image.img_to_array(img4)\n",
        "            img4 = img4.astype('float32')\n",
        "            img4 /= 255\n",
        "\n",
        "            vl_pairs += [[img3, img4]]  \n",
        "            vl_labels += [[0]]  ## why not tr_labels += [0]\n",
        "            \n",
        "            # except\n",
        "              \n",
        "    print(counter, len(vl_pairs))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 564\n",
            "2 1128\n",
            "3 1692\n",
            "4 2352\n",
            "5 2916\n",
            "6 3480\n",
            "7 4044\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "86YH4c3rm-xi",
        "outputId": "dfbe8c95-e286-437a-edbe-43f1f896da13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "cell_type": "code",
      "source": [
        "# Test Data\n",
        "\n",
        "te_pairs = []\n",
        "te_labels = []\n",
        "\n",
        "for counter, author3 in enumerate(authors[48:], 1):\n",
        "    gen_dir3 = os.path.join(BASE_DIR, author3, 'Genuine')\n",
        "    for_dir3 = os.path.join(BASE_DIR, author3, 'Forged')\n",
        "\n",
        "    gen_list3 = os.listdir(gen_dir3)\n",
        "    for_list3 = os.listdir(for_dir3)\n",
        "\n",
        "    gen_num3 = len(gen_list3)\n",
        "    for_num3 = len(for_list3)\n",
        "\n",
        "    # Genuine-Genuine\n",
        "    for i in range(gen_num3):\n",
        "        for j in range(i+1, gen_num3):\n",
        "            file1 = gen_list3[i]\n",
        "            file2 = gen_list3[j]\n",
        "            \n",
        "            try:\n",
        "              img1 = image.load_img(os.path.join(gen_dir3, file1), grayscale = True, target_size=(height, width))\n",
        "              img1 = image.img_to_array(img1)\n",
        "              img1 = img1.astype('float32')\n",
        "              img1 /= 255\n",
        "\n",
        "              img2 = image.load_img(os.path.join(gen_dir3, file2), grayscale = True, target_size=(height, width))\n",
        "              img2 = image.img_to_array(img2)\n",
        "              img2 = img2.astype('float32')\n",
        "              img2 /= 255\n",
        "\n",
        "              te_pairs += [[img1, img2]] \n",
        "              te_labels += [[1]]  ## why not tr_labels += [1]\n",
        "              \n",
        "            except:\n",
        "              a = 2\n",
        "\n",
        "    # Genuine-Forged\n",
        "    for k in range(gen_num2):\n",
        "        for l in range(for_num2):\n",
        "            file3 = gen_list2[k]\n",
        "            file4 = for_list2[l]\n",
        "\n",
        "            try:\n",
        "              img3 = image.load_img(os.path.join(gen_dir3, file3), grayscale = True, target_size=(height, width))\n",
        "              img3 = image.img_to_array(img3)\n",
        "              img3 = img3.astype('float32')\n",
        "              img3 /= 255\n",
        "\n",
        "              img4 = image.load_img(os.path.join(for_dir3, file4), grayscale = True, target_size=(height, width))\n",
        "              img4 = image.img_to_array(img4)\n",
        "              img4 = img4.astype('float32')\n",
        "              img4 /= 255\n",
        "\n",
        "              te_pairs += [[img3, img4]]  \n",
        "              te_labels += [[0]]  ## why not tr_labels += [0]\n",
        "            \n",
        "            except:\n",
        "              a = 2\n",
        "              \n",
        "    print(counter, len(te_pairs))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 276\n",
            "2 552\n",
            "3 828\n",
            "4 1104\n",
            "5 1380\n",
            "6 1656\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "b69jJmF-JOdu",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## Potential errors\n",
        "\n",
        "tr_pairs = np.asarray(tr_pairs)\n",
        "tr_labels = np.asarray(tr_labels)\n",
        "vl_pairs = np.asarray(vl_pairs)\n",
        "vl_labels = np.asarray(vl_labels)\n",
        "te_pairs = np.asarray(te_pairs)\n",
        "te_labels = np.asarray(te_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Ha4iZ9QX-cBl",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## Potential errors\n",
        "\n",
        "tr_pairs = tr_pairs.reshape(tr_pairs.shape[0], height, width, 1)  # Added new\n",
        "vl_pairs = vl_pairs.reshape(vl_pairs.shape[0], height, width, 1)\n",
        "te_pairs = te_pairs.reshape(te_pairs.shape[0], height, width, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "uXtozQgz4oLG",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Defining the model\n",
        "def siamese_base(input_shape):\n",
        "    seq = Sequential()\n",
        "    seq.add(layers.Conv2D(64, (7, 7), activation = 'relu', strides = (2, 2), input_shape = input_shape))  ## kernel_initializer = 'glorot_uniform'\n",
        "    seq.add(layers.BatchNormalization(epsilon = 1e-06, axis = 3, momentum = 0.9))\n",
        "    seq.add(layers.MaxPooling2D((3, 3), strides = (2, 2)))\n",
        "    seq.add(layers.ZeroPadding2D((2, 2), ))\n",
        "\n",
        "    seq.add(layers.Conv2D(128, (5, 5), activation = 'relu', strides = (1, 1)))  ## kernel_initializer = 'glorot_uniform'\n",
        "    seq.add(layers.BatchNormalization(epsilon = 1e-06, axis = 1, momentum = 0.9))\n",
        "    seq.add(layers.MaxPooling2D((3, 3), strides = (2, 2)))\n",
        "    seq.add(layers.ZeroPadding2D((1, 1), ))\n",
        "\n",
        "    seq.add(layers.Conv2D(256, (5, 5), activation = 'relu', strides = (1, 1)))  ## kernel_initializer = 'glorot_uniform'\n",
        "    seq.add(layers.MaxPooling2D((3, 3), strides = (2, 2)))\n",
        "    seq.add(layers.Dropout(0.3))\n",
        "    seq.add(layers.ZeroPadding2D((1, 1), ))\n",
        "\n",
        "    seq.add(layers.Conv2D(256, (3, 3), activation = 'relu', strides = (1, 1)))  ## kernel_initializer = 'glorot_uniform'\n",
        "    seq.add(layers.MaxPooling2D((3, 3), strides = (2, 2)))\n",
        "    seq.add(layers.Dropout(0.3))\n",
        "\n",
        "    seq.add(layers.Flatten())\n",
        "    seq.add(layers.Dense(1024, kernel_regularizer = regularizers.l2(0.0005), activation = 'relu'))  ## kernel_initializer = 'glorot_uniform'\n",
        "    seq.add(layers.Dropout(0.5))\n",
        "\n",
        "    seq.add(layers.Dense(128, kernel_regularizer = regularizers.l2(0.0005), activation = 'relu'))  ## kernel_initializer = 'glorot_uniform'\n",
        "    print(seq.summary())\n",
        "    return seq"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "mXq9UnCh4rxw",
        "outputId": "8bb219f2-5de6-482a-f0b0-fe1a9a34dd4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 845
        }
      },
      "cell_type": "code",
      "source": [
        "base_network = siamese_base(input_shape)\n",
        "input_a = Input(shape = (input_shape))\n",
        "input_b = Input(shape = (input_shape))\n",
        "processed_a = base_network(input_a)\n",
        "processed_b = base_network(input_b)  # Sharing of weights\n",
        "\n",
        "distance = Lambda(euclidean_distance, output_shape=eucl_dist_output_shape)([processed_a, processed_b])\n",
        "\n",
        "model = Model(inputs = [input_a, input_b], outputs = distance)\n",
        "\n",
        "rms = optimizers.RMSprop(lr = 1e-4, rho = 0.9, epsilon = 1e-8)\n",
        "model.compile(loss = contrastive_loss, optimizer = rms, metrics = ['acc'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_9 (Conv2D)            (None, 125, 125, 64)      3200      \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 125, 125, 64)      256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 (None, 62, 62, 64)        0         \n",
            "_________________________________________________________________\n",
            "zero_padding2d_7 (ZeroPaddin (None, 66, 66, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 62, 62, 128)       204928    \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 62, 62, 128)       248       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling (None, 30, 30, 128)       0         \n",
            "_________________________________________________________________\n",
            "zero_padding2d_8 (ZeroPaddin (None, 32, 32, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 28, 28, 256)       819456    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling (None, 13, 13, 256)       0         \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 13, 13, 256)       0         \n",
            "_________________________________________________________________\n",
            "zero_padding2d_9 (ZeroPaddin (None, 15, 15, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 13, 13, 256)       590080    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_12 (MaxPooling (None, 6, 6, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 6, 6, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 9216)              0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1024)              9438208   \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 128)               131200    \n",
            "=================================================================\n",
            "Total params: 11,187,576\n",
            "Trainable params: 11,187,324\n",
            "Non-trainable params: 252\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "0Zc6c0wQ4zpH",
        "outputId": "70c1b167-8d73-484a-ee92-7a3f4c33a5b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 567
        }
      },
      "cell_type": "code",
      "source": [
        "history = model.fit([tr_pairs[:, 0], tr_pairs[:, 1]], tr_labels, epochs = epochs, batch_size = batch_size, validation_data = ([vl_pairs[:, 0], vl_pairs[:, 1]], vl_labels))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-715e23836f49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtr_pairs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtr_pairs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtr_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvl_pairs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvl_pairs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvl_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1628\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1629\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1630\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1631\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1632\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m   1474\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1475\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1476\u001b[0;31m                                     exception_prefix='input')\n\u001b[0m\u001b[1;32m   1477\u001b[0m         y = _standardize_input_data(y, self._feed_output_names,\n\u001b[1;32m   1478\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    111\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    114\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected input_1 to have 4 dimensions, but got array with shape (0, 256, 1)"
          ]
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "64uKrLul43ew",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# model.save(os.path.join(BASE_DIR, 'model2x2.h5'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "NFI1I2Nu5ESA",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "epochs = range(1, 21)\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "c_7OpjZb5HoS",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Training vs Validation Loss\n",
        "\n",
        "plt.plot(epochs, loss, 'ro', label = 'Training Loss')\n",
        "plt.plot(epochs, val_loss, 'r', label = 'Validation Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "EjvFb6ie5KVB",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Training vs Validation Accuracy\n",
        "\n",
        "plt.plot(epochs, acc, 'ro', label = 'Training Accuracy')\n",
        "plt.plot(epochs, val_acc, 'r', label = 'Validation Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "sS5ONdlV5M4u",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pred = model.predict([te_pairs[:, 0], te_pairs[:, 1]])\n",
        "acc = model.evaluate([te_pairs[:, 0], te_pairs[:, 1]], te_labels)\n",
        "te_acc = compute_accuracy(pred, te_labels)\n",
        "roc_acc = compute_accuracy_roc(pred, te_labels)\n",
        "print(acc, te_acc, roc_acc)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}